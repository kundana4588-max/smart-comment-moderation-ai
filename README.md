# Smart Comment Moderation System

## Problem Statement
Online social media platforms face increasing issues with toxic comments,
hate speech, harassment, and cyberbullying. Most moderation systems act
after damage is done.

## Proposed Solution
This project proposes an AI-powered preventive comment moderation system
that analyzes comments before they are posted and prevents harmful content
from reaching the community.

## Key Features
- Real-time comment analysis
- Detection of hate speech, harassment, bullying, and threats
- Supports mixed-language text like Hinglish and Tinglish
- Preventive moderation approach (Allow / Warn / Block)
- Simple Instagram-style comment interface

## Technology Stack
- Python
- Streamlit
- NLP (Natural Language Processing)
- Machine Learning models

## How It Works
1. User types a comment.
2. AI analyzes the comment.
3. Comment is classified as:
   - Safe
   - Mild Toxic (warning shown)
   - Severe Toxic (blocked)
4. Only safe comments are allowed to be posted.

## How to Run the Project
## Project Status
This is a working prototype built for hackathon submission.
